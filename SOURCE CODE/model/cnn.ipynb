{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import *\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df= pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8</td>\n",
       "      <td>3-Nov-15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161292</th>\n",
       "      <td>191035</td>\n",
       "      <td>Campral</td>\n",
       "      <td>Alcohol Dependence</td>\n",
       "      <td>\"I wrote my first report in Mid-October of 201...</td>\n",
       "      <td>10</td>\n",
       "      <td>31-May-15</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161293</th>\n",
       "      <td>127085</td>\n",
       "      <td>Metoclopramide</td>\n",
       "      <td>Nausea/Vomiting</td>\n",
       "      <td>\"I was given this in IV before surgey. I immed...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-Nov-11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161294</th>\n",
       "      <td>187382</td>\n",
       "      <td>Orencia</td>\n",
       "      <td>Rheumatoid Arthritis</td>\n",
       "      <td>\"Limited improvement after 4 months, developed...</td>\n",
       "      <td>2</td>\n",
       "      <td>15-Mar-14</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161295</th>\n",
       "      <td>47128</td>\n",
       "      <td>Thyroid desiccated</td>\n",
       "      <td>Underactive Thyroid</td>\n",
       "      <td>\"I&amp;#039;ve been on thyroid medication 49 years...</td>\n",
       "      <td>10</td>\n",
       "      <td>19-Sep-15</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161296</th>\n",
       "      <td>215220</td>\n",
       "      <td>Lubiprostone</td>\n",
       "      <td>Constipation, Chronic</td>\n",
       "      <td>\"I&amp;#039;ve had chronic constipation all my adu...</td>\n",
       "      <td>9</td>\n",
       "      <td>13-Dec-14</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161297 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uniqueID                  drugName                     condition  \\\n",
       "0         206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1          95260                Guanfacine                          ADHD   \n",
       "2          92703                    Lybrel                 Birth Control   \n",
       "3         138000                Ortho Evra                 Birth Control   \n",
       "4          35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "...          ...                       ...                           ...   \n",
       "161292    191035                   Campral            Alcohol Dependence   \n",
       "161293    127085            Metoclopramide               Nausea/Vomiting   \n",
       "161294    187382                   Orencia          Rheumatoid Arthritis   \n",
       "161295     47128        Thyroid desiccated           Underactive Thyroid   \n",
       "161296    215220              Lubiprostone         Constipation, Chronic   \n",
       "\n",
       "                                                   review  rating       date  \\\n",
       "0       \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1       \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2       \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "3       \"This is my first time using any form of birth...       8   3-Nov-15   \n",
       "4       \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
       "...                                                   ...     ...        ...   \n",
       "161292  \"I wrote my first report in Mid-October of 201...      10  31-May-15   \n",
       "161293  \"I was given this in IV before surgey. I immed...       1   1-Nov-11   \n",
       "161294  \"Limited improvement after 4 months, developed...       2  15-Mar-14   \n",
       "161295  \"I&#039;ve been on thyroid medication 49 years...      10  19-Sep-15   \n",
       "161296  \"I&#039;ve had chronic constipation all my adu...       9  13-Dec-14   \n",
       "\n",
       "        usefulCount  \n",
       "0                27  \n",
       "1               192  \n",
       "2                17  \n",
       "3                10  \n",
       "4                37  \n",
       "...             ...  \n",
       "161292          125  \n",
       "161293           34  \n",
       "161294           35  \n",
       "161295           79  \n",
       "161296          116  \n",
       "\n",
       "[161297 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 161297 entries, 0 to 161296\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   uniqueID     161297 non-null  int64 \n",
      " 1   drugName     161297 non-null  object\n",
      " 2   condition    160398 non-null  object\n",
      " 3   review       161297 non-null  object\n",
      " 4   rating       161297 non-null  int64 \n",
      " 5   date         161297 non-null  object\n",
      " 6   usefulCount  161297 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "sms_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniqueID         0\n",
       "drugName         0\n",
       "condition      899\n",
       "review           0\n",
       "rating           0\n",
       "date             0\n",
       "usefulCount      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df=sms_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 160398 entries, 0 to 161296\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   uniqueID     160398 non-null  int64 \n",
      " 1   drugName     160398 non-null  object\n",
      " 2   condition    160398 non-null  object\n",
      " 3   review       160398 non-null  object\n",
      " 4   rating       160398 non-null  int64 \n",
      " 5   date         160398 non-null  object\n",
      " 6   usefulCount  160398 non-null  int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "sms_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1599: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "E:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "E:\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "sms_df.loc[sms_df['rating']<=5, 'expression']  = 1\n",
    "sms_df.loc[sms_df['rating']>=6, 'expression'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = sms_df['review']\n",
    "labels = sms_df['expression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_texts, test_texts, other_labels, test_labels  = train_test_split(texts, labels, test_size=0.1, random_state=302)\n",
    "#Create validation sample\n",
    "train_texts, valid_texts, train_labels, valid_labels  = train_test_split(other_texts, other_labels, test_size=0.2, random_state=302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "# Convert words into word ids\n",
    "meanLength = np.mean([len(item.split(\" \")) for item in train_texts])\n",
    "MAX_SENTENCE_LENGTH = int(meanLength + 5) # we let a text go 10 words longer than the mean text length.\n",
    "\n",
    "# Convert train, validation, and test text into lists with word ids\n",
    "trainFeatures = tokenizer.texts_to_sequences(train_texts)\n",
    "trainFeatures = pad_sequences(trainFeatures, MAX_SENTENCE_LENGTH, padding='post')\n",
    "trainLabels = train_labels.values\n",
    "\n",
    "validFeatures = tokenizer.texts_to_sequences(valid_texts)\n",
    "validFeatures = pad_sequences(validFeatures, MAX_SENTENCE_LENGTH, padding='post')\n",
    "validLabels = valid_labels.values\n",
    "\n",
    "testFeatures = tokenizer.texts_to_sequences(test_texts)\n",
    "testFeatures = pad_sequences(testFeatures, MAX_SENTENCE_LENGTH, padding='post')\n",
    "testLabels = test_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SENTENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS_SIZE = 16\n",
    "KERNEL_SIZE = 5\n",
    "\n",
    "# Define embeddings dimensions (columns in matrix fed into CNN and nodes in hidden layer of built-in keras function)\n",
    "EMBEDDINGS_DIM = 11\n",
    "\n",
    "# Hyperparameters for model tuning\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 90, 11)            275011    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 86, 16)            896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 86, 16)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 276,052\n",
      "Trainable params: 276,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Word CNN\n",
    "model = Sequential()\n",
    "\n",
    "# We use built-in keras funtion to generate embeddings. Another option is pre-trained embeddings with Word2vec or GloVe.\n",
    "model.add(Embedding(input_dim=VOCABULARY_SIZE + 1, output_dim=EMBEDDINGS_DIM, input_length=len(trainFeatures[0])))\n",
    "model.add(Conv1D(FILTERS_SIZE, KERNEL_SIZE, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "            \n",
    "optimizer = optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3609/3609 [==============================] - 20s 6ms/step - loss: 0.4962 - accuracy: 0.7602 - val_loss: 0.4454 - val_accuracy: 0.8198\n",
      "Epoch 2/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.4118 - accuracy: 0.8140 - val_loss: 0.4185 - val_accuracy: 0.8327\n",
      "Epoch 3/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.3817 - accuracy: 0.8305 - val_loss: 0.4154 - val_accuracy: 0.8349\n",
      "Epoch 4/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.3602 - accuracy: 0.8422 - val_loss: 0.4096 - val_accuracy: 0.8340\n",
      "Epoch 5/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.3441 - accuracy: 0.8492 - val_loss: 0.4012 - val_accuracy: 0.8354\n",
      "Epoch 6/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.3301 - accuracy: 0.8565 - val_loss: 0.3953 - val_accuracy: 0.8363\n",
      "Epoch 7/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.3194 - accuracy: 0.8610 - val_loss: 0.4111 - val_accuracy: 0.8306\n",
      "Epoch 8/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.3073 - accuracy: 0.8659 - val_loss: 0.4032 - val_accuracy: 0.8356\n",
      "Epoch 9/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2982 - accuracy: 0.8705 - val_loss: 0.3986 - val_accuracy: 0.8300\n",
      "Epoch 10/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2900 - accuracy: 0.8740 - val_loss: 0.3938 - val_accuracy: 0.8286\n",
      "Epoch 11/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2805 - accuracy: 0.8787 - val_loss: 0.4042 - val_accuracy: 0.8292\n",
      "Epoch 12/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2752 - accuracy: 0.8797 - val_loss: 0.3876 - val_accuracy: 0.8334\n",
      "Epoch 13/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2674 - accuracy: 0.8825 - val_loss: 0.3986 - val_accuracy: 0.8195\n",
      "Epoch 14/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2599 - accuracy: 0.8859 - val_loss: 0.3993 - val_accuracy: 0.8209\n",
      "Epoch 15/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2567 - accuracy: 0.8866 - val_loss: 0.4169 - val_accuracy: 0.8087\n",
      "Epoch 16/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2503 - accuracy: 0.8899 - val_loss: 0.4097 - val_accuracy: 0.8133\n",
      "Epoch 17/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2467 - accuracy: 0.8914 - val_loss: 0.4124 - val_accuracy: 0.8135\n",
      "Epoch 18/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2409 - accuracy: 0.8941 - val_loss: 0.3878 - val_accuracy: 0.8230\n",
      "Epoch 19/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2375 - accuracy: 0.8945 - val_loss: 0.3915 - val_accuracy: 0.8240\n",
      "Epoch 20/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2332 - accuracy: 0.8965 - val_loss: 0.3909 - val_accuracy: 0.8232\n",
      "Epoch 21/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2300 - accuracy: 0.8973 - val_loss: 0.3990 - val_accuracy: 0.8212\n",
      "Epoch 22/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2265 - accuracy: 0.8989 - val_loss: 0.4113 - val_accuracy: 0.8181\n",
      "Epoch 23/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2258 - accuracy: 0.8992 - val_loss: 0.4053 - val_accuracy: 0.8179\n",
      "Epoch 24/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2206 - accuracy: 0.9011 - val_loss: 0.4039 - val_accuracy: 0.8159\n",
      "Epoch 25/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2189 - accuracy: 0.9008 - val_loss: 0.4010 - val_accuracy: 0.8198\n",
      "Epoch 26/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2157 - accuracy: 0.9032 - val_loss: 0.4062 - val_accuracy: 0.8177\n",
      "Epoch 27/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2132 - accuracy: 0.9033 - val_loss: 0.4119 - val_accuracy: 0.8107\n",
      "Epoch 28/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2121 - accuracy: 0.9040 - val_loss: 0.4260 - val_accuracy: 0.8069\n",
      "Epoch 29/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2086 - accuracy: 0.9059 - val_loss: 0.4146 - val_accuracy: 0.8085\n",
      "Epoch 30/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2067 - accuracy: 0.9052 - val_loss: 0.4336 - val_accuracy: 0.7971\n",
      "Epoch 31/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2057 - accuracy: 0.9058 - val_loss: 0.4084 - val_accuracy: 0.8149\n",
      "Epoch 32/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.2035 - accuracy: 0.9062 - val_loss: 0.4178 - val_accuracy: 0.8078\n",
      "Epoch 33/50\n",
      "3609/3609 [==============================] - 18s 5ms/step - loss: 0.2012 - accuracy: 0.9068 - val_loss: 0.4152 - val_accuracy: 0.8101\n",
      "Epoch 34/50\n",
      "3609/3609 [==============================] - 18s 5ms/step - loss: 0.1993 - accuracy: 0.9078 - val_loss: 0.4303 - val_accuracy: 0.7999\n",
      "Epoch 35/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1982 - accuracy: 0.9077 - val_loss: 0.4233 - val_accuracy: 0.8069\n",
      "Epoch 36/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1960 - accuracy: 0.9089 - val_loss: 0.4057 - val_accuracy: 0.8147\n",
      "Epoch 37/50\n",
      "3609/3609 [==============================] - 18s 5ms/step - loss: 0.1952 - accuracy: 0.9080 - val_loss: 0.4337 - val_accuracy: 0.8037\n",
      "Epoch 38/50\n",
      "3609/3609 [==============================] - 18s 5ms/step - loss: 0.1941 - accuracy: 0.9094 - val_loss: 0.4136 - val_accuracy: 0.8104\n",
      "Epoch 39/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1925 - accuracy: 0.9083 - val_loss: 0.4114 - val_accuracy: 0.8117\n",
      "Epoch 40/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1929 - accuracy: 0.9094 - val_loss: 0.4223 - val_accuracy: 0.8063\n",
      "Epoch 41/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1895 - accuracy: 0.9103 - val_loss: 0.4106 - val_accuracy: 0.8148\n",
      "Epoch 42/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1904 - accuracy: 0.9095 - val_loss: 0.4063 - val_accuracy: 0.8156\n",
      "Epoch 43/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1884 - accuracy: 0.9107 - val_loss: 0.3998 - val_accuracy: 0.8304\n",
      "Epoch 44/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1867 - accuracy: 0.9093 - val_loss: 0.4075 - val_accuracy: 0.8154\n",
      "Epoch 45/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1854 - accuracy: 0.9123 - val_loss: 0.4166 - val_accuracy: 0.8113\n",
      "Epoch 46/50\n",
      "3609/3609 [==============================] - 18s 5ms/step - loss: 0.1853 - accuracy: 0.9123 - val_loss: 0.4173 - val_accuracy: 0.8132\n",
      "Epoch 47/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1849 - accuracy: 0.9121 - val_loss: 0.4224 - val_accuracy: 0.8070\n",
      "Epoch 48/50\n",
      "3609/3609 [==============================] - 18s 5ms/step - loss: 0.1837 - accuracy: 0.9118 - val_loss: 0.4206 - val_accuracy: 0.8120\n",
      "Epoch 49/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1837 - accuracy: 0.9128 - val_loss: 0.4338 - val_accuracy: 0.8016\n",
      "Epoch 50/50\n",
      "3609/3609 [==============================] - 19s 5ms/step - loss: 0.1815 - accuracy: 0.9128 - val_loss: 0.4286 - val_accuracy: 0.8102\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainFeatures, trainLabels, validation_data = (validFeatures, validLabels), batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "twt = [\"WASHINGTON/JERUSALEM (Reuters) - During his 20\"]\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   148 1368  139  134   21  417]]\n",
      "1/1 - 0s\n",
      "[0.00733402]\n"
     ]
    }
   ],
   "source": [
    "twt = pad_sequences(twt, maxlen=720, dtype='int32', value=0)\n",
    "print(twt)\n",
    "sentiment = model.predict(twt,batch_size=20,verbose = 2)[0]\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "output_dir = re.sub('Model and data', 'Flask application', current_dir)\n",
    "os.chdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b0e3a337d457f6e167ef5be9f5008698193d9285ec48eaca4504cedeb33f098"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
